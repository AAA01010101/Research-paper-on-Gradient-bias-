# -*- coding: utf-8 -*-
"""project_ods.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17q0lCA34u91MuzXKQGfHZSZXbouMh0hZ
"""

import numpy as np
import matplotlib.pyplot as plt
class MultiObjectiveOptimizer:
    def __init__(self, objectives):
        self.objectives = objectives

    def optimize(self, x0, learning_rate=0.01, num_iterations=1000):
        x = np.array(x0, dtype=float)  # x is float type
        x_history = [x.copy()]  # Store the history of parameter values
        for _ in range(num_iterations):
            gradients = self.compute_gradients(x)
            x -= learning_rate * gradients
            x_history.append(x.copy())
        return np.array(x_history)

    def compute_gradients(self, x):
        gradients = np.zeros_like(x)
        for obj in self.objectives:
            obj_gradient = obj.gradient(x)
            gradients += obj_gradient
        return gradients

class ObjectiveFunction:
    def __init__(self, function):
        self.function = function

    def evaluate(self, x):
        return self.function(x)

    def gradient(self, x, epsilon=1e-5):
        grad = np.zeros_like(x)
        for i in range(len(x)):
            x_plus = np.copy(x)
            x_plus[i] += epsilon
            x_minus = np.copy(x)
            x_minus[i] -= epsilon
            grad[i] = (self.function(x_plus) - self.function(x_minus)) / (2 * epsilon)
        return grad

# # Example usage
# def objective1(x):
#     return x[0] ** 2 + x[1] ** 2

# def objective2(x):
#     return (x[0] - 1) ** 2 + (x[1] - 1) ** 2

# Define the objective functions
def objective1(x):
    return np.sin(x[0]) + np.cos(x[1])

def objective2(x):
    return np.exp(-(x[0] - 1) ** 2) + np.exp(-(x[1] - 1) ** 2)

obj1 = ObjectiveFunction(objective1)
obj2 = ObjectiveFunction(objective2)

# Plot the objective functions
x_range = np.linspace(-3, 3, 100)
y_range = np.linspace(-3, 3, 100)
X, Y = np.meshgrid(x_range, y_range)
Z1 = obj1.evaluate([X, Y])
Z2 = obj2.evaluate([X, Y])

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.contourf(X, Y, Z1, cmap='viridis')
plt.colorbar(label='Objective 1 Value')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Objective Function 1')

plt.subplot(1, 2, 2)
plt.contourf(X, Y, Z2, cmap='viridis')
plt.colorbar(label='Objective 2 Value')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Objective Function 2')

plt.tight_layout()
plt.show()



optimizer = MultiObjectiveOptimizer([obj1, obj2])
initial_guess = [0.0, 0.0]  # Initial guess as floats
optimal_solution = optimizer.optimize(initial_guess)
history = optimizer.optimize(initial_guess)

print("Optimal solution:", optimal_solution)
print("Objective 1 value:", obj1.evaluate(optimal_solution))
print("Objective 2 value:", obj2.evaluate(optimal_solution))

# Plot the optimization path on the objective function graph
plt.figure(figsize=(8, 6))
plt.contourf(X, Y, Z1, cmap='viridis', alpha=0.5)
plt.contourf(X, Y, Z2, cmap='viridis', alpha=0.5)
plt.plot(history[:, 0], history[:, 1], '-ro', label='Optimization Path')
plt.xlabel('Objective 1')
plt.ylabel('Objective 2')
plt.title('Multi-Objective Optimization with MoCo')
plt.legend()
plt.grid(True)
plt.show()

# Plot the objective space
x = np.linspace(-1, 3, 100)
y1 = obj1.evaluate(x)
y2 = obj2.evaluate(x)

plt.figure(figsize=(8, 6))
plt.plot(y1, y2, label='Objective Space')
plt.scatter(history[:, 0] ** 2, history[:, 1] ** 2, c='red', label='Optimization Path')
plt.xlabel('Objective 1')
plt.ylabel('Objective 2')
plt.title('Multi-Objective Optimization with MoCo')
plt.legend()
plt.grid(True)
plt.show()

